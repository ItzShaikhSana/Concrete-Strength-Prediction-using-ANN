## **Concrete Strength Prediction using ANN**

This project aims to predict the compressive strength of concrete using an Artificial Neural Network (ANN) model. The dataset contains 8 input features related to concrete mix design and curing age, which significantly influence its final strength.


**ğŸ”¶ Features Used**

- Cement: Amount of cement in kg/mÂ³.

- Blast Furnace Slag: Enhances durability and strength.

- Fly Ash: Improves long-term strength.

- Water: Crucial for hydration; needs optimal proportion.

- Superplasticizer: Increases workability without extra water.

- Coarse Aggregate: Adds strength and reduces cement usage.

- Fine Aggregate: Fills voids; improves density.

- Age: Number of days since casting; strength increases with time.
  

**âš™ï¸ Data Preprocessing**

Dataset split into training and testing sets.

Applied standardization to features (mean = 0, std = 1).

**ğŸ—ï¸ Model Architecture**

ğŸ“Œ Model 1

5 Hidden Layers: 100 â†’ 60 â†’ 80 â†’ 90 â†’ 100 neurons (ReLU activation)

Output Layer: 1 neuron (Sigmoid activation)

Loss Function: mean_squared_error

**Final Training Loss: ~1475.88, Validation Loss: ~1526.57**

ğŸ“Œ Model 2

3 Hidden Layers: 40 â†’ 50 â†’ 60 neurons (ReLU activation)

Output Layer: 1 neuron (Linear activation)

Loss Function: mean_squared_error

**Final Training Loss: ~30.01, Validation Loss: ~36.57**

ğŸ› ï¸ Technologies Used

Python

TensorFlow / Keras

NumPy

Pandas

Scikit-learn

Matplotlib / Seaborn (optional for EDA)

**âœ… Conclusion**

ANNs were effectively used to model the complex nonlinear relationship between concrete mix components and compressive strength. Model 2 significantly outperformed Model 1 with much lower loss values, indicating better generalization and predictive accuracy.

**ğŸš€ Future Work**

Perform hyperparameter tuning (learning rate, batch size, number of layers).

Evaluate using cross-validation and more metrics (MAE, RÂ²).

Try regularization techniques (Dropout, L2) to reduce overfitting.

Experiment with other models like Random Forest or XGBoost for comparison.

Deploy model using Streamlit or Flask for user interaction.


